{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2791ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_is_pandas_df' from 'sklearn.utils.validation' (/home/rahel/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/sklearn/utils/validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/__init__.py:52\u001b[39m\n\u001b[32m     48\u001b[39m     sys.stderr.write(\u001b[33m\"\u001b[39m\u001b[33mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m         combine,\n\u001b[32m     54\u001b[39m         ensemble,\n\u001b[32m     55\u001b[39m         exceptions,\n\u001b[32m     56\u001b[39m         metrics,\n\u001b[32m     57\u001b[39m         over_sampling,\n\u001b[32m     58\u001b[39m         pipeline,\n\u001b[32m     59\u001b[39m         tensorflow,\n\u001b[32m     60\u001b[39m         under_sampling,\n\u001b[32m     61\u001b[39m         utils,\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/combine/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mSMOTEENN\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSMOTETomek\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/combine/_smote_enn.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/base.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/utils/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     check_neighbors_object,\n\u001b[32m      8\u001b[39m     check_sampling_strategy,\n\u001b[32m      9\u001b[39m     check_target_type,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m __all__ = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_neighbors_object\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_sampling_strategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_target_type\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSubstitution\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/utils/_validation.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[32m     22\u001b[39m SAMPLING_KIND = (\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mover-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munder-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbypass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m TARGET_KIND = (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultilabel-indicator\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/imblearn/utils/_sklearn_compat.py:256\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata_routing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    253\u001b[39m         _raise_for_params,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    254\u001b[39m         process_routing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    255\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    257\u001b[39m         _is_fitted,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    258\u001b[39m         _is_pandas_df,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    259\u001b[39m     )\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# Upgrading for scikit-learn 1.5\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sklearn_version < parse_version(\u001b[33m\"\u001b[39m\u001b[33m1.5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# chunking\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;66;03m# extmath\u001b[39;00m\n\u001b[32m    270\u001b[39m     \u001b[38;5;66;03m# fixes\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_is_pandas_df' from 'sklearn.utils.validation' (/home/rahel/Desktop/Improved detection of frauds/venv/lib/python3.12/site-packages/sklearn/utils/validation.py)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98123b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load processed data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m fraud_df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/processed/fraud_data_processed.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m credit_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/processed/creditcard_processed.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFraud data shape:\u001b[39m\u001b[33m\"\u001b[39m, fraud_df.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "fraud_df = pd.read_csv('../data/processed/fraud_data_processed.csv')\n",
    "credit_df = pd.read_csv('../data/processed/creditcard_processed.csv')\n",
    "\n",
    "print(\"Fraud data shape:\", fraud_df.shape)\n",
    "print(\"Credit card data shape:\", credit_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cc918",
   "metadata": {},
   "source": [
    "## Fraud_Data.csv Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267150b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features added to fraud data\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamps back to datetime if needed\n",
    "fraud_df['signup_time'] = pd.to_datetime(fraud_df['signup_time'])\n",
    "fraud_df['purchase_time'] = pd.to_datetime(fraud_df['purchase_time'])\n",
    "\n",
    "# Additional time features\n",
    "fraud_df['signup_dayofweek'] = fraud_df['signup_time'].dt.dayofweek\n",
    "fraud_df['purchase_dayofweek'] = fraud_df['purchase_time'].dt.dayofweek\n",
    "fraud_df['is_weekend_signup'] = fraud_df['signup_dayofweek'].isin([5, 6]).astype(int)\n",
    "fraud_df['is_weekend_purchase'] = fraud_df['purchase_dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Transaction velocity features (simplified - in real scenario would need user history)\n",
    "# For demo, we'll create proxy features\n",
    "fraud_df['hourly_transaction_density'] = fraud_df.groupby('purchase_hour')['purchase_value'].transform('count')\n",
    "fraud_df['device_transaction_count'] = fraud_df.groupby('device_id')['device_id'].transform('count')\n",
    "\n",
    "print(\"Additional features added to fraud data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62906fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['purchase_value', 'age', 'time_since_signup', 'signup_hour', 'signup_day', 'signup_month', 'purchase_hour', 'purchase_day', 'purchase_month', 'signup_dayofweek', 'purchase_dayofweek', 'hourly_transaction_density', 'device_transaction_count']\n",
      "Categorical columns: ['source', 'browser', 'sex', 'country']\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for modeling\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address', 'ip_address_int']\n",
    "fraud_features = fraud_df.drop(cols_to_drop + ['class'], axis=1)\n",
    "fraud_target = fraud_df['class']\n",
    "\n",
    "# Identify column types\n",
    "numerical_cols = ['purchase_value', 'age', 'time_since_signup', 'signup_hour', 'signup_day', \n",
    "                  'signup_month', 'purchase_hour', 'purchase_day', 'purchase_month',\n",
    "                  'signup_dayofweek', 'purchase_dayofweek', 'hourly_transaction_density', \n",
    "                  'device_transaction_count']\n",
    "categorical_cols = ['source', 'browser', 'sex', 'country']\n",
    "\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7abd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed fraud data shape: (151112, 24)\n",
      "Number of features: 24\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipeline\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Fit and transform\n",
    "X_fraud_processed = preprocessor.fit_transform(fraud_features)\n",
    "\n",
    "# Get feature names\n",
    "num_feature_names = numerical_cols\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "feature_names = np.concatenate([num_feature_names, cat_feature_names])\n",
    "\n",
    "print(\"Processed fraud data shape:\", X_fraud_processed.shape)\n",
    "print(\"Number of features:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77458f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apply SMOTE for class imbalance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m smote = \u001b[43mSMOTE\u001b[49m(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      3\u001b[39m X_fraud_smote, y_fraud_smote = smote.fit_resample(X_fraud_processed, fraud_target)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal class distribution:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE for class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_fraud_smote, y_fraud_smote = smote.fit_resample(X_fraud_processed, fraud_target)\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(fraud_target.value_counts())\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(pd.Series(y_fraud_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d76c1",
   "metadata": {},
   "source": [
    "## Credit Card Data Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647360e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card data preprocessing (minimal since already PCA transformed)\n",
    "X_credit = credit_df.drop('Class', axis=1)\n",
    "y_credit = credit_df['Class']\n",
    "\n",
    "# Scale Amount and Time\n",
    "scaler = StandardScaler()\n",
    "X_credit_scaled = scaler.fit_transform(X_credit)\n",
    "\n",
    "print(\"Credit card data shape:\", X_credit_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to credit card data\n",
    "X_credit_smote, y_credit_smote = smote.fit_resample(X_credit_scaled, y_credit)\n",
    "\n",
    "print(\"Original credit card class distribution:\")\n",
    "print(y_credit.value_counts())\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(pd.Series(y_credit_smote).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets\n",
    "import joblib\n",
    "\n",
    "# Save fraud data\n",
    "joblib.dump(X_fraud_smote, '../data/processed/X_fraud_smote.pkl')\n",
    "joblib.dump(y_fraud_smote, '../data/processed/y_fraud_smote.pkl')\n",
    "joblib.dump(feature_names, '../data/processed/fraud_feature_names.pkl')\n",
    "\n",
    "# Save credit card data\n",
    "joblib.dump(X_credit_smote, '../data/processed/X_credit_smote.pkl')\n",
    "joblib.dump(y_credit_smote, '../data/processed/y_credit_smote.pkl')\n",
    "\n",
    "# Save preprocessors\n",
    "joblib.dump(preprocessor, '../models/fraud_preprocessor.pkl')\n",
    "joblib.dump(scaler, '../models/credit_scaler.pkl')\n",
    "\n",
    "print(\"All processed data and models saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
